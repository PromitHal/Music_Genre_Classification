{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6e80b36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded, Shape : 10000 ,343\n",
      "Data Loaded, Shape : 10000 ,343\n",
      "Model: \"model_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_14 (InputLayer)       [(None, 341)]             0         \n",
      "                                                                 \n",
      " dense_65 (Dense)            (None, 512)               175104    \n",
      "                                                                 \n",
      " dense_66 (Dense)            (None, 1024)              525312    \n",
      "                                                                 \n",
      " dense_67 (Dense)            (None, 2048)              2099200   \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_68 (Dense)            (None, 512)               1049088   \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_69 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,853,834\n",
      "Trainable params: 3,853,834\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "Epoch 1/40\n",
      "100/100 [==============================] - 13s 92ms/step - loss: 1.2929 - acc: 0.5595 - val_loss: 0.8032 - val_acc: 0.7244 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "100/100 [==============================] - 9s 94ms/step - loss: 0.7034 - acc: 0.7678 - val_loss: 0.5818 - val_acc: 0.8075 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "100/100 [==============================] - 9s 88ms/step - loss: 0.4919 - acc: 0.8391 - val_loss: 0.5925 - val_acc: 0.8169 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "100/100 [==============================] - 8s 84ms/step - loss: 0.3749 - acc: 0.8770 - val_loss: 0.4587 - val_acc: 0.8512 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "100/100 [==============================] - 8s 83ms/step - loss: 0.3728 - acc: 0.8836 - val_loss: 0.4161 - val_acc: 0.8644 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "100/100 [==============================] - 8s 83ms/step - loss: 0.2736 - acc: 0.9127 - val_loss: 0.4567 - val_acc: 0.8675 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "100/100 [==============================] - 8s 83ms/step - loss: 0.2150 - acc: 0.9342 - val_loss: 0.4581 - val_acc: 0.8600 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 0.1963 - acc: 0.9370 - val_loss: 0.4207 - val_acc: 0.8825 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "100/100 [==============================] - 8s 85ms/step - loss: 0.2000 - acc: 0.9406 - val_loss: 0.3729 - val_acc: 0.9056 - lr: 0.0010\n",
      "Epoch 10/40\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 0.1660 - acc: 0.9480 - val_loss: 0.4584 - val_acc: 0.8781 - lr: 0.0010\n",
      "Epoch 11/40\n",
      "100/100 [==============================] - 8s 85ms/step - loss: 0.1610 - acc: 0.9491 - val_loss: 0.4635 - val_acc: 0.8800 - lr: 0.0010\n",
      "Epoch 12/40\n",
      "100/100 [==============================] - 10s 96ms/step - loss: 0.1280 - acc: 0.9609 - val_loss: 0.4504 - val_acc: 0.8888 - lr: 0.0010\n",
      "Epoch 13/40\n",
      "100/100 [==============================] - 10s 100ms/step - loss: 0.1422 - acc: 0.9567 - val_loss: 0.3935 - val_acc: 0.8913 - lr: 0.0010\n",
      "Epoch 14/40\n",
      "100/100 [==============================] - 9s 93ms/step - loss: 0.0841 - acc: 0.9703 - val_loss: 0.4990 - val_acc: 0.9031 - lr: 0.0010\n",
      "Epoch 15/40\n",
      "100/100 [==============================] - 9s 91ms/step - loss: 0.1497 - acc: 0.9620 - val_loss: 0.4759 - val_acc: 0.8894 - lr: 0.0010\n",
      "Epoch 16/40\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1566 - acc: 0.9523\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "100/100 [==============================] - 9s 91ms/step - loss: 0.1566 - acc: 0.9523 - val_loss: 0.4567 - val_acc: 0.8788 - lr: 0.0010\n",
      "Epoch 17/40\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 0.0682 - acc: 0.9789 - val_loss: 0.3449 - val_acc: 0.9206 - lr: 1.0000e-04\n",
      "Epoch 18/40\n",
      "100/100 [==============================] - 9s 93ms/step - loss: 0.0287 - acc: 0.9917 - val_loss: 0.3409 - val_acc: 0.9206 - lr: 1.0000e-04\n",
      "Epoch 19/40\n",
      "100/100 [==============================] - 10s 95ms/step - loss: 0.0212 - acc: 0.9939 - val_loss: 0.3384 - val_acc: 0.9287 - lr: 1.0000e-04\n",
      "Epoch 20/40\n",
      "100/100 [==============================] - 9s 93ms/step - loss: 0.0163 - acc: 0.9962 - val_loss: 0.3599 - val_acc: 0.9225 - lr: 1.0000e-04\n",
      "Epoch 21/40\n",
      "100/100 [==============================] - 9s 93ms/step - loss: 0.0168 - acc: 0.9950 - val_loss: 0.3463 - val_acc: 0.9325 - lr: 1.0000e-04\n",
      "Epoch 22/40\n",
      "100/100 [==============================] - 9s 93ms/step - loss: 0.0118 - acc: 0.9958 - val_loss: 0.3557 - val_acc: 0.9325 - lr: 1.0000e-04\n",
      "Epoch 23/40\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 0.0087 - acc: 0.9980 - val_loss: 0.3559 - val_acc: 0.9350 - lr: 1.0000e-04\n",
      "Epoch 24/40\n",
      "100/100 [==============================] - 9s 91ms/step - loss: 0.0079 - acc: 0.9978 - val_loss: 0.3586 - val_acc: 0.9369 - lr: 1.0000e-04\n",
      "Epoch 25/40\n",
      "100/100 [==============================] - 9s 89ms/step - loss: 0.0057 - acc: 0.9984 - val_loss: 0.3667 - val_acc: 0.9369 - lr: 1.0000e-04\n",
      "Epoch 26/40\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0059 - acc: 0.9984\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "100/100 [==============================] - 10s 95ms/step - loss: 0.0059 - acc: 0.9984 - val_loss: 0.3671 - val_acc: 0.9375 - lr: 1.0000e-04\n",
      "Epoch 27/40\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 0.0043 - acc: 0.9992 - val_loss: 0.3674 - val_acc: 0.9388 - lr: 1.0000e-05\n",
      "Epoch 28/40\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 0.0036 - acc: 0.9994 - val_loss: 0.3685 - val_acc: 0.9388 - lr: 1.0000e-05\n",
      "Epoch 29/40\n",
      "100/100 [==============================] - 9s 88ms/step - loss: 0.0033 - acc: 0.9995 - val_loss: 0.3694 - val_acc: 0.9381 - lr: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras import Sequential\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from keras.models import Model\n",
    "from Data import DataLoader\n",
    "from DataLoader import Data\n",
    "import xgboost as xgb\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "df=Data.load_data('music.csv')\n",
    "\n",
    "path_filename=r'C:\\Users\\PROMIT\\Desktop\\Music_Genre\\music_01.csv'\n",
    "label_dict={\n",
    "    'final_blues':0,\n",
    "    'final_classical':1,\n",
    "    'final_country':2,\n",
    "    'final_disco':3,\n",
    "    'final_hiphop':4,\n",
    "    'final_jazz':5,\n",
    "    'final_metal':6,\n",
    "    'final_pop':7,\n",
    "    'final_reggae':8,\n",
    "    'final_rock':9\n",
    "}\n",
    "df=Data.load_data('music.csv')\n",
    "\n",
    "trainx,testx,trainy,testy=Data.prepare_data(df,label_dict={\n",
    "    'final_blues':0,\n",
    "    'final_classical':1,\n",
    "    'final_country':2,\n",
    "    'final_disco':3,\n",
    "    'final_hiphop':4,\n",
    "    'final_jazz':5,\n",
    "    'final_metal':6,\n",
    "    'final_pop':7,\n",
    "    'final_reggae':8,\n",
    "    'final_rock':9\n",
    "})    \n",
    "sc=StandardScaler()\n",
    "\n",
    "trainx=sc.fit_transform(trainx)\n",
    "testx=sc.transform(testx)\n",
    "num_epochs=40\n",
    "\n",
    "class Model:\n",
    "    def __init__(self,input_shape,num_classes):\n",
    "        self.input_shape=input_shape\n",
    "        self.num_classes=num_classes\n",
    "\n",
    "    def build_model(self):\n",
    "       inputs=tf.keras.Input(shape=self.input_shape)\n",
    "       layer1=tf.keras.layers.Dense(512,activation='relu')(inputs)\n",
    "       layer2=tf.keras.layers.Dense(1024,activation='relu')(layer1)\n",
    "       layer3=tf.keras.layers.Dense(2048,activation='relu')(layer2)\n",
    "       layer4=tf.keras.layers.Dropout(rate=0.4)(layer3)\n",
    "       layer5=tf.keras.layers.Dense(512,activation='relu')(layer4)\n",
    "       layer6=tf.keras.layers.Dropout(rate=0.5)(layer5)\n",
    "       layer5=tf.keras.layers.Dense(self.num_classes,activation='softmax')(layer6)\n",
    "       model=tf.keras.Model(inputs=inputs,outputs=layer5)\n",
    "\n",
    "       return model\n",
    "    \n",
    "        \n",
    "\n",
    "model=Model(input_shape=(341),num_classes=10)\n",
    "model=model.build_model()\n",
    "print(model.summary())\n",
    "\n",
    "params={\n",
    "    'batch_size':64,\n",
    "    'epochs':40,\n",
    "    'validation_split':0.2\n",
    "}\n",
    "\n",
    "def train_model(model,trainx,trainy,params):\n",
    "    \n",
    "    earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n",
    "    mcp_save = ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "    reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=7, verbose=1, epsilon=1e-4, mode='min')    \n",
    "    model.compile(optimizer='Adam',loss='sparse_categorical_crossentropy',metrics='acc')\n",
    "    model.fit(trainx,trainy,batch_size=params['batch_size'],validation_split=params['validation_split'],epochs=params['epochs'],callbacks=[earlyStopping, mcp_save, reduce_lr_loss])\n",
    "    \n",
    "\n",
    "train_model(model,trainx,trainy,params)\n",
    "\n",
    "# preds=model(testx)\n",
    "# preds=np.array(preds)\n",
    "# preds=np.argmax(preds,axis=1)\n",
    "# preds=np.array(preds,dtype='int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6e7ac69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 7ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.944004132825814"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds=model.predict(testx)\n",
    "f1_score(testy,np.argmax(preds,axis=1),average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b2f4a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MMR_Feature_Extract import MMR_Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e40a450a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=MMR_Selection(trainx,trainy,alpha=0.5)\n",
    "indices,trainx=data.get_cols(matrix=trainx,num_features=100)\n",
    "trainx=trainx[:,indices]\n",
    "def apply_valid(valid_data,index_list):\n",
    "    valid_data=valid_data[:,index_list]\n",
    "    return valid_data\n",
    "validx=apply_valid(valid_data=testx,index_list=indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e19ee816",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_valid(valid_data,index_list):\n",
    "    valid_data=valid_data[:,index_list]\n",
    "    return valid_data\n",
    "validx=apply_valid(valid_data=testx,index_list=indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49581b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_11 (InputLayer)       [(None, 100)]             0         \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 512)               51712     \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 1024)              525312    \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 2048)              2099200   \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 512)               1049088   \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_54 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,730,442\n",
      "Trainable params: 3,730,442\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "Epoch 1/40\n",
      "100/100 [==============================] - 12s 103ms/step - loss: 1.1497 - acc: 0.5969 - val_loss: 0.7864 - val_acc: 0.7356 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "100/100 [==============================] - 10s 104ms/step - loss: 0.6272 - acc: 0.7914 - val_loss: 0.5677 - val_acc: 0.8050 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "100/100 [==============================] - 10s 102ms/step - loss: 0.4430 - acc: 0.8589 - val_loss: 0.6074 - val_acc: 0.8094 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "100/100 [==============================] - 11s 107ms/step - loss: 0.3076 - acc: 0.8983 - val_loss: 0.4402 - val_acc: 0.8556 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "100/100 [==============================] - 11s 106ms/step - loss: 0.2349 - acc: 0.9255 - val_loss: 0.4076 - val_acc: 0.8806 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "100/100 [==============================] - 10s 103ms/step - loss: 0.1760 - acc: 0.9423 - val_loss: 0.4063 - val_acc: 0.8856 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "100/100 [==============================] - 10s 104ms/step - loss: 0.1718 - acc: 0.9481 - val_loss: 0.6273 - val_acc: 0.8594 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "100/100 [==============================] - 10s 103ms/step - loss: 0.1573 - acc: 0.9525 - val_loss: 0.4164 - val_acc: 0.8900 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "100/100 [==============================] - 10s 104ms/step - loss: 0.1296 - acc: 0.9597 - val_loss: 0.4283 - val_acc: 0.8919 - lr: 0.0010\n",
      "Epoch 10/40\n",
      "100/100 [==============================] - 10s 103ms/step - loss: 0.1068 - acc: 0.9663 - val_loss: 0.4433 - val_acc: 0.8894 - lr: 0.0010\n",
      "Epoch 11/40\n",
      "100/100 [==============================] - 10s 103ms/step - loss: 0.0982 - acc: 0.9708 - val_loss: 0.4545 - val_acc: 0.8881 - lr: 0.0010\n",
      "Epoch 12/40\n",
      "100/100 [==============================] - 10s 102ms/step - loss: 0.0789 - acc: 0.9773 - val_loss: 0.4538 - val_acc: 0.9013 - lr: 0.0010\n",
      "Epoch 13/40\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0808 - acc: 0.9750\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.0808 - acc: 0.9750 - val_loss: 0.4070 - val_acc: 0.9094 - lr: 0.0010\n",
      "Epoch 14/40\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.0278 - acc: 0.9920 - val_loss: 0.3497 - val_acc: 0.9244 - lr: 1.0000e-04\n",
      "Epoch 15/40\n",
      "100/100 [==============================] - 12s 124ms/step - loss: 0.0133 - acc: 0.9975 - val_loss: 0.3479 - val_acc: 0.9250 - lr: 1.0000e-04\n",
      "Epoch 16/40\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0106 - acc: 0.9975 - val_loss: 0.3533 - val_acc: 0.9262 - lr: 1.0000e-04\n",
      "Epoch 17/40\n",
      "100/100 [==============================] - 14s 136ms/step - loss: 0.0077 - acc: 0.9986 - val_loss: 0.3537 - val_acc: 0.9281 - lr: 1.0000e-04\n",
      "Epoch 18/40\n",
      "100/100 [==============================] - 12s 122ms/step - loss: 0.0066 - acc: 0.9986 - val_loss: 0.3610 - val_acc: 0.9287 - lr: 1.0000e-04\n",
      "Epoch 19/40\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.0055 - acc: 0.9986 - val_loss: 0.3634 - val_acc: 0.9294 - lr: 1.0000e-04\n",
      "Epoch 20/40\n",
      "100/100 [==============================] - 11s 109ms/step - loss: 0.0040 - acc: 0.9992 - val_loss: 0.3681 - val_acc: 0.9300 - lr: 1.0000e-04\n",
      "Epoch 21/40\n",
      "100/100 [==============================] - 10s 95ms/step - loss: 0.0037 - acc: 0.9995 - val_loss: 0.3747 - val_acc: 0.9294 - lr: 1.0000e-04\n",
      "Epoch 22/40\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "100/100 [==============================] - 9s 95ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.3817 - val_acc: 0.9300 - lr: 1.0000e-04\n",
      "Epoch 23/40\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0028 - acc: 0.9995 - val_loss: 0.3820 - val_acc: 0.9300 - lr: 1.0000e-05\n",
      "Epoch 24/40\n",
      "100/100 [==============================] - 11s 108ms/step - loss: 0.0026 - acc: 0.9997 - val_loss: 0.3823 - val_acc: 0.9300 - lr: 1.0000e-05\n",
      "Epoch 25/40\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0027 - acc: 0.9997 - val_loss: 0.3828 - val_acc: 0.9306 - lr: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "class Model:\n",
    "    def __init__(self,input_shape,num_classes):\n",
    "        self.input_shape=input_shape\n",
    "        self.num_classes=num_classes\n",
    "\n",
    "    def build_model(self):\n",
    "       inputs=tf.keras.Input(shape=self.input_shape)\n",
    "       layer1=tf.keras.layers.Dense(512,activation='relu')(inputs)\n",
    "       layer2=tf.keras.layers.Dense(1024,activation='relu')(layer1)\n",
    "       layer3=tf.keras.layers.Dense(2048,activation='relu')(layer2)\n",
    "       layer4=tf.keras.layers.Dropout(rate=0.4)(layer3)\n",
    "       layer5=tf.keras.layers.Dense(512,activation='relu')(layer4)\n",
    "       layer6=tf.keras.layers.Dropout(rate=0.5)(layer5)\n",
    "       layer5=tf.keras.layers.Dense(self.num_classes,activation='softmax')(layer6)\n",
    "       model=tf.keras.Model(inputs=inputs,outputs=layer5)\n",
    "\n",
    "       return model\n",
    "def train_model(model,trainx,trainy,params):\n",
    "    \n",
    "    earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n",
    "    mcp_save = ModelCheckpoint('.compressed_mdl_wts.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "    reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=7, verbose=1, epsilon=1e-4, mode='min')    \n",
    "    model.compile(optimizer='Adam',loss='sparse_categorical_crossentropy',metrics='acc')\n",
    "    model.fit(trainx,trainy,batch_size=params['batch_size'],validation_split=params['validation_split'],epochs=params['epochs'],callbacks=[earlyStopping, mcp_save, reduce_lr_loss])\n",
    "    \n",
    "       \n",
    "        \n",
    "model=Model(input_shape=(100),num_classes=10)\n",
    "model=model.build_model()\n",
    "print(model.summary())\n",
    "train_model(model,trainx,trainy,params)\n",
    "\n",
    "preds=model(validx)\n",
    "preds=np.array(preds)\n",
    "preds=np.argmax(preds,axis=1)\n",
    "preds=np.array(preds,dtype='int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d1116a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds=np.argmax(preds,axis=1)\n",
    "f1_score(testy,preds,average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5a3dc23a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9386503753594369"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds=np.argmax(preds,axis=1)\n",
    "f1_score(testy,preds,average='macro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f972210a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_13 (InputLayer)       [(None, 100)]             0         \n",
      "                                                                 \n",
      " dense_60 (Dense)            (None, 512)               51712     \n",
      "                                                                 \n",
      " dense_61 (Dense)            (None, 1024)              525312    \n",
      "                                                                 \n",
      " dense_62 (Dense)            (None, 2048)              2099200   \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 512)               1049088   \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_64 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,730,442\n",
      "Trainable params: 3,730,442\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "Epoch 1/40\n",
      "100/100 [==============================] - 16s 143ms/step - loss: 1.1848 - acc: 0.5927 - val_loss: 0.6955 - val_acc: 0.7706 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "100/100 [==============================] - 13s 134ms/step - loss: 0.5406 - acc: 0.8248 - val_loss: 0.5483 - val_acc: 0.8175 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "100/100 [==============================] - 13s 135ms/step - loss: 0.3381 - acc: 0.8881 - val_loss: 0.4500 - val_acc: 0.8462 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "100/100 [==============================] - 13s 127ms/step - loss: 0.2115 - acc: 0.9319 - val_loss: 0.3654 - val_acc: 0.8931 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "100/100 [==============================] - 12s 123ms/step - loss: 0.1348 - acc: 0.9567 - val_loss: 0.3839 - val_acc: 0.8925 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.1199 - acc: 0.9636 - val_loss: 0.3486 - val_acc: 0.9050 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.0795 - acc: 0.9736 - val_loss: 0.4648 - val_acc: 0.8906 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "100/100 [==============================] - 11s 107ms/step - loss: 0.1070 - acc: 0.9677 - val_loss: 0.3642 - val_acc: 0.9100 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.0555 - acc: 0.9827 - val_loss: 0.4838 - val_acc: 0.8969 - lr: 0.0010\n",
      "Epoch 10/40\n",
      "100/100 [==============================] - 11s 106ms/step - loss: 0.0792 - acc: 0.9791 - val_loss: 0.4280 - val_acc: 0.8981 - lr: 0.0010\n",
      "Epoch 11/40\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.0477 - acc: 0.9858 - val_loss: 0.4517 - val_acc: 0.9087 - lr: 0.0010\n",
      "Epoch 12/40\n",
      "100/100 [==============================] - 13s 128ms/step - loss: 0.0339 - acc: 0.9894 - val_loss: 0.4434 - val_acc: 0.9175 - lr: 0.0010\n",
      "Epoch 13/40\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0451 - acc: 0.9881\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "100/100 [==============================] - 12s 118ms/step - loss: 0.0451 - acc: 0.9881 - val_loss: 0.5271 - val_acc: 0.9031 - lr: 0.0010\n",
      "Epoch 14/40\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.0234 - acc: 0.9931 - val_loss: 0.3766 - val_acc: 0.9244 - lr: 1.0000e-04\n",
      "Epoch 15/40\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0063 - acc: 0.9992 - val_loss: 0.3603 - val_acc: 0.9281 - lr: 1.0000e-04\n",
      "Epoch 16/40\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.0037 - acc: 0.9995 - val_loss: 0.3649 - val_acc: 0.9262 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pc=PCA(n_components=100)\n",
    "trainx=pc.fit_transform(trainx)\n",
    "testx=pc.transform(testx)\n",
    "\n",
    "class Model:\n",
    "    def __init__(self,input_shape,num_classes):\n",
    "        self.input_shape=input_shape\n",
    "        self.num_classes=num_classes\n",
    "\n",
    "    def build_model(self):\n",
    "       inputs=tf.keras.Input(shape=self.input_shape)\n",
    "       layer1=tf.keras.layers.Dense(512,activation='relu')(inputs)\n",
    "       layer2=tf.keras.layers.Dense(1024,activation='relu')(layer1)\n",
    "       layer3=tf.keras.layers.Dense(2048,activation='relu')(layer2)\n",
    "       layer4=tf.keras.layers.Dropout(rate=0.4)(layer3)\n",
    "       layer5=tf.keras.layers.Dense(512,activation='relu')(layer4)\n",
    "       layer6=tf.keras.layers.Dropout(rate=0.5)(layer5)\n",
    "       layer5=tf.keras.layers.Dense(self.num_classes,activation='softmax')(layer6)\n",
    "       model=tf.keras.Model(inputs=inputs,outputs=layer5)\n",
    "\n",
    "       return model\n",
    "def train_model(model,trainx,trainy,params):\n",
    "    \n",
    "    earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n",
    "    mcp_save = ModelCheckpoint('.compressed_mdl_wts.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "    reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=7, verbose=1, epsilon=1e-4, mode='min')    \n",
    "    model.compile(optimizer='Adam',loss='sparse_categorical_crossentropy',metrics='acc')\n",
    "    model.fit(trainx,trainy,batch_size=params['batch_size'],validation_split=params['validation_split'],epochs=params['epochs'],callbacks=[earlyStopping, mcp_save, reduce_lr_loss])\n",
    "    \n",
    "       \n",
    "        \n",
    "model=Model(input_shape=(100),num_classes=10)\n",
    "model=model.build_model()\n",
    "print(model.summary())\n",
    "train_model(model,trainx,trainy,params)\n",
    "\n",
    "preds=model(validx)\n",
    "preds=np.array(preds)\n",
    "preds=np.argmax(preds,axis=1)\n",
    "preds=np.array(preds,dtype='int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2087f970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 1s 10ms/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "preds=model.predict(testx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "24e44879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9296928823575117"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds=np.argmax(preds,axis=1)\n",
    "f1_score(testy,preds,average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5941bdc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b598b12f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aac5ae4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
